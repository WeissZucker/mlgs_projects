{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "# These packages are required by the visualization utils\n",
    "import seaborn as sns  \n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import vae_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1, part 2: Variational Autoencoder (60 pt)\n",
    "In this notebook you will implement the Variational Autoencoder (VAE) that we discussed in Lecture 3.\n",
    "\n",
    "## Your task\n",
    "Complete the missing code. Make sure that all the functions follow the provided specification, i.e. the output of the function exactly matches the description in the docstring. \n",
    "\n",
    "Do not add or modify any code outside of the following comment blocks\n",
    "```\n",
    "##########################################################\n",
    "# YOUR CODE HERE\n",
    ".....\n",
    "##########################################################\n",
    "```\n",
    "After you fill in all the missing code, restart the kernel and re-run all the cells in the notebook.\n",
    "\n",
    "\n",
    "The following things are **NOT** allowed:\n",
    "- Using additional `import` statements\n",
    "- Using the `torch.distributions` package\n",
    "- Copying / reusing code from other sources (e.g. code by other students)\n",
    "\n",
    "If you plagiarise even for a single project task, you won't be eligible for the bonus this semester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "device = 'cpu'  # uncomment this line to run the model on the CPU\n",
    "batch_size = 128\n",
    "dataset = datasets.MNIST \n",
    "if device == 'cuda':\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset('data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset('data', train=False, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=1000, shuffle=True, num_workers=1, pin_memory=True\n",
    "    )\n",
    "elif device == 'cpu':\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset('data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=batch_size, shuffle=True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset('data', train=False, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=1000, shuffle=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize a few random samples from the dataset\n",
    "vae_utils.visualize_mnist(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Encoder (10 pt)\n",
    "The encoder network produces the parameters of the variational distribution (Slide 102). \n",
    "In our case, the variational distribution $q_{\\boldsymbol{\\phi}^{(i)}}(\\mathbf{z}^{(i)})$ is multivariate normal with diagonal covariance, so we encoder needs to produce its mean and the (diagonal of the) covariance matrix.\n",
    "The encoder has the following architecture\n",
    "<img src=\"img/encoder.png\" alt=\"Encoder\" style=\"width: 200px;\"/>\n",
    "The encoder produces the parameters $\\boldsymbol{\\mu}^{(i)} \\in \\mathbb{R}^L$ and $\\log \\boldsymbol{\\sigma}^{(i)} \\in \\mathbb{R}^L$ for each sample $i$ in the mini batch. \n",
    "Note that $\\log \\boldsymbol{\\sigma}^{(i)}$ can be negative, we convert it into a diagonal positive-definite covariance matrix as $\\boldsymbol{\\Sigma}^{(i)} = \\operatorname{diag}(\\exp(\\log \\boldsymbol{\\sigma}^{(i)}))^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Reparametrization sampling (10 pt)\n",
    "Given the parameters $\\boldsymbol{\\mu}^{(i)}$ and $\\log \\boldsymbol{\\sigma}^{(i)}$ of the variational distribution, we need to generate samples $\\mathbf{z}^{(i)} \\sim q_{\\boldsymbol{\\phi}^{(i)}}(\\mathbf{z}^{(i)}) = \\mathcal{N}(\\mathbf{z}^{(i)} | \\boldsymbol{\\mu}^{(i)}, \\boldsymbol{\\Sigma}^{(i)})$ to estimate the ELBO. \n",
    "We draw one sample $\\mathbf{z}^{(i)}$ for each instance $i$ in the mini-batch (Slide 104).\n",
    "It's important to draw samples using reparametrization here, so that it's possible to obtain gradient w.r.t. the parameters of the encoder.\n",
    "\n",
    "Functions `torch.normal` or `torch.Tensor.normal_` might be useful here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Decoder (10 pt)\n",
    "The decoder takes the samples $\\mathbf{z}^{(i)}$ and produces the parameters $\\boldsymbol{\\theta}^{(i)} \\in \\mathbb{R}^D$ of the data likelihood $p_{\\boldsymbol{\\theta}^{(i)}}(\\mathbf{x}^{(i)}|\\mathbf{z}^{(i)})$.\n",
    "We use the following simple architecture for the decoder\n",
    "\n",
    "<img src=\"img/decoder.png\" alt=\"Decoder\" style=\"width: 150px;\"/>\n",
    "\n",
    "Our data $\\mathbf{x}^{(i)} \\in \\{0, 1\\}^D$ is binary, so we use Bernoulli likelihood (Slide 95)\n",
    "$$p_{\\boldsymbol{\\theta}^{(i)}}(\\mathbf{x}^{(i)}|\\mathbf{z}^{(i)}) = \\prod_{j=1}^D \\left(\\theta_{j}^{(i)}\\right)^{x_{j}^{(i)}} \\left(1 - \\theta_{j}^{(i)}\\right)^{1 - x_{j}^{(i)}}$$\n",
    "Recall that the **negative log-likelihood** of the Bernoulli model is also called binary cross entropy.\n",
    "\n",
    "The parameters $\\theta_{j}^{(i)}$ must be in $(0, 1)$, which we enforce using the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: KL divergence (5 pt)\n",
    "To compute the ELBO, we will need to compute the KL divergence. \n",
    "$$\\mathbb{KL}(q_{\\boldsymbol{\\phi}^{(i)}}(\\mathbf{z}^{(i)}) || p(\\mathbf{z}^{(i)}))$$\n",
    "Where $p(\\mathbf{z}^{(i)})$ is the standard L-dimensional normal distribution (zero mean, identity covariance).\n",
    "This can be done in closed form (Slide 99)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: ELBO (15 pt)\n",
    "Finally, we can compute the ELBO using all the methods that we implemented above.\n",
    "ELBO for a single sample $\\mathbf{x}^{(i)} \\in \\{0, 1\\}^D$ is computed as\n",
    "$$\\mathcal{L}_i(\\boldsymbol{\\psi}, \\boldsymbol{\\lambda}) = \\mathbb{E}_{\\mathbf{z}^{(i)} \\sim q_{\\boldsymbol{\\phi}^{(i)}} (\\mathbf{z}^{(i)})}\\left[\\log p_{\\boldsymbol{\\theta}^{(i)}}(\\mathbf{x}^{(i)} | \\mathbf{z}^{(i)})\\right] - \\mathbb{KL}(q_{\\boldsymbol{\\phi}^{(i)}}(\\mathbf{z}^{(i)}) || p(\\mathbf{z}))$$\n",
    "\n",
    "In practice it's more efficient to compute the ELBO for a minibatch $\\mathcal{B}$ of samples \n",
    "$$\\mathcal{L}(\\boldsymbol{\\psi}, \\boldsymbol{\\lambda}) = \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x}^{(i)} \\in \\mathcal{B}} \\mathcal{L}_i(\\boldsymbol{\\psi}, \\boldsymbol{\\lambda})$$\n",
    "where the variational parameters $\\boldsymbol{\\phi}^{(i)}$ are produced by the **encoder network** $f_{\\boldsymbol{\\psi}}$ (i.e. $\\boldsymbol{\\phi}^{(i)} = f_{\\boldsymbol{\\psi}}(\\mathbf{x}^{(i)})$),\n",
    "and the likelihood parameters $\\boldsymbol{\\theta}^{(i)}$ are produced by the **decoder network** $g_{\\boldsymbol{\\lambda}}$ (i.e. $\\boldsymbol{\\theta}^{(i)} = g_{\\boldsymbol{\\lambda}}(\\mathbf{x}^{(i)})$).\n",
    "\n",
    "Overview of this procedure is provided on Slide 103."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Generating new data (10 pt)\n",
    "We can generate new samples using the procedure described on Slide 108.\n",
    "Function `torch.bernoulli` might be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, obs_dim, latent_dim, hidden_dim=100):\n",
    "        \"\"\"Initialize the VAE model.\n",
    "        \n",
    "        Args:\n",
    "            obs_dim: Dimension of the observed data x, int\n",
    "            latent_dim: Dimension of the latent variable z, int\n",
    "            hidden_dim: Hidden dimension of the encoder/decoder networks, int\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        # Trainable layers of the encoder\n",
    "        self.linear1 = nn.Linear(obs_dim, hidden_dim)\n",
    "        self.linear21 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.linear22 = nn.Linear(hidden_dim, latent_dim)\n",
    "        # Trainable layers of the decoder\n",
    "        self.linear3 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.linear4 = nn.Linear(hidden_dim, obs_dim)\n",
    "    \n",
    "    def encoder(self, x):\n",
    "        \"\"\"Obtain the parameters of q(z) for a batch of data points.\n",
    "        \n",
    "        Args:\n",
    "            x: Batch of data points, shape [batch_size, obs_dim]\n",
    "        \n",
    "        Returns:\n",
    "            mu: Means of q(z), shape [batch_size, latent_dim]\n",
    "            logsigma: Log-sigmas of q(z), shape [batch_size, latent_dim]\n",
    "        \"\"\"\n",
    "        ##########################################################\n",
    "        # YOUR CODE HERE\n",
    "        o = F.relu(self.linear1(x))\n",
    "        mu = self.linear21(o)\n",
    "        logsigma = self.linear22(o)\n",
    "        \n",
    "        return mu, logsigma\n",
    "        \n",
    "        ##########################################################\n",
    "    \n",
    "    def sample_with_reparam(self, mu, logsigma):\n",
    "        \"\"\"Draw sample from q(z) with reparametrization.\n",
    "        \n",
    "        We draw a single sample z_i for each data point x_i.\n",
    "        \n",
    "        Args:\n",
    "            mu: Means of q(z) for the batch, shape [batch_size, latent_dim]\n",
    "            logsigma: Log-sigmas of q(z) for the batch, shape [batch_size, latent_dim]\n",
    "        \n",
    "        Returns:\n",
    "            z: Latent variables samples from q(z), shape [batch_size, latent_dim]\n",
    "        \"\"\"\n",
    "        ##########################################################\n",
    "        # YOUR CODE HERE\n",
    "        epsilon = torch.normal(torch.zeros_like(mu), torch.ones_like(mu))\n",
    "        z = mu + torch.exp(logsigma) * epsilon\n",
    "        \n",
    "        return z\n",
    "        ##########################################################\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        \"\"\"Convert sampled latent variables z into observations x.\n",
    "        \n",
    "        Args:\n",
    "            z: Sampled latent variables, shape [batch_size, latent_dim]\n",
    "        \n",
    "        Returns:\n",
    "            theta: Parameters of the conditional likelihood, shape [batch_size, obs_dim]\n",
    "        \"\"\"\n",
    "        ##########################################################\n",
    "        # YOUR CODE HERE\n",
    "        theta = F.relu(self.linear3(z))\n",
    "        theta = self.linear4(theta)\n",
    "        theta = torch.sigmoid(theta)\n",
    "        \n",
    "        return theta\n",
    "        ##########################################################\n",
    "    \n",
    "    def kl_divergence(self, mu, logsigma):\n",
    "        \"\"\"Compute KL divergence KL(q_i(z)||p(z)) for each q_i in the batch.\n",
    "        \n",
    "        Args:\n",
    "            mu: Means of the q_i distributions, shape [batch_size, latent_dim]\n",
    "            logsigma: Logarithm of standard deviations of the q_i distributions,\n",
    "                      shape [batch_size, latent_dim]\n",
    "        \n",
    "        Returns:\n",
    "            kl: KL divergence for each of the q_i distributions, shape [batch_size]\n",
    "        \"\"\"\n",
    "        ##########################################################\n",
    "        # YOUR CODE HERE\n",
    "        return 0.5 * (torch.sum(torch.exp(logsigma)**2 + mu ** 2 - 2*logsigma - 1, dim=1))\n",
    "        ##########################################################\n",
    "    \n",
    "    def elbo(self, x):\n",
    "        \"\"\"Estimate the ELBO for the mini-batch of data.\n",
    "        \n",
    "        Args:\n",
    "            x: Mini-batch of the observations, shape [batch_size, obs_dim]\n",
    "        \n",
    "        Returns:\n",
    "            elbo_mc: MC estimate of ELBO for each sample in the mini-batch, shape [batch_size]\n",
    "        \"\"\"\n",
    "        ##########################################################\n",
    "        # YOUR CODE HERE\n",
    "        mu, logsigma = self.encoder(x)\n",
    "        z = self.sample_with_reparam(mu, logsigma)\n",
    "        theta = self.decoder(z)\n",
    "        log_p_x_z = - F.binary_cross_entropy(theta, x, reduction='none')\n",
    "        log_p_x_z = torch.sum(log_p_x_z, dim=1)\n",
    "        kl = self.kl_divergence(mu, logsigma)\n",
    "        \n",
    "        return torch.mean(log_p_x_z - kl)\n",
    "        ##########################################################\n",
    "        \n",
    "    def sample(self, num_samples):\n",
    "        \"\"\"Generate samples from the model.\n",
    "        \n",
    "        Args:\n",
    "            num_samples: Number of samples to generate.\n",
    "        \n",
    "        Returns:\n",
    "            x: Samples generated by the model, shape [num_samples, obs_dim]\n",
    "        \"\"\"\n",
    "        ##########################################################\n",
    "        # YOUR CODE HERE\n",
    "        z_sample = torch.randn((num_samples, self.latent_dim))\n",
    "        theta = self.decoder(z_sample)\n",
    "        return torch.bernoulli(theta)\n",
    "        ##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim = 784  # MNIST images are of shape [1, 28, 28]\n",
    "latent_dim = 32  # Size of the latent variable z\n",
    "hidden_dim = 400  # Size of the hidden layer in the encoder / decoder\n",
    "\n",
    "vae = VAE(obs_dim, latent_dim, hidden_dim).to(device)\n",
    "opt = torch.optim.Adam(vae.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "  loss = 551.18\n",
      "  loss = 183.53\n",
      "  loss = 159.27\n",
      "  loss = 144.27\n",
      "  loss = 141.34\n",
      "Epoch 1\n",
      "  loss = 130.17\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "display_step = 100\n",
    "for epoch in range(max_epochs):\n",
    "    print(f'Epoch {epoch}')\n",
    "    for ix, batch in enumerate(train_loader):\n",
    "        x, y = batch\n",
    "        x = x.view(x.shape[0], obs_dim).to(device)  # we flatten the image into 1D array\n",
    "        opt.zero_grad()\n",
    "        # We want to maximize the ELBO, so we minimize the negative ELBO\n",
    "        loss = -vae.elbo(x).mean(-1)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        if ix % display_step == 0:\n",
    "            print(f'  loss = {loss.item():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize samples generated by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.empty((128, 32, 32))\n",
    "b = torch.empty((128, 32, 1))\n",
    "torch.bmm(a, b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vae.sample(10).view(-1, 28, 28).detach().cpu().numpy()\n",
    "vae_utils.visualize_vae_samples(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the images here look somewhat similar to the training data and it's possible to discern the shapes of different digits, the sampels are not visually coherent.\n",
    "You might need to run the above cell several times to obtain images that look decent.\n",
    "\n",
    "It's possible to obtain images that look a lot better by using more \n",
    "powerful encoders & decoders (see `nn.Conv2d` and `nn.ConvTranspose2d`).\n",
    "However, training such models is slower, unless you have a good GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the embeddings produced by the model\n",
    "Here, we visualize the embeddings learned by the encoder using the following procedure\n",
    "1. Take a mini-batch `x` (shape `[batch_size, obs_dim]`)\n",
    "2. Pass `x` through the encoder \n",
    "```\n",
    "mu, logsigma = vae.encoder(x)\n",
    "```\n",
    "3. Visualize the mean `mu` for each sample using t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(test_loader))\n",
    "x = x.view(x.shape[0], obs_dim).to(device)\n",
    "plt.figure(figsize=[10, 7])\n",
    "vae_utils.visualize_embeddings(vae, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the encoder learned to assign similar means to the images that belong to the same class. That means, if two samples $x_i$ and $x_j$ belong to the same class, the means $\\mu_i$ and $\\mu_j$ of their variational distributions $q_i(z_i)$ and $q_j(z_j)$ are nearby, so $z_i$ and $z_j$ will likely be close as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
